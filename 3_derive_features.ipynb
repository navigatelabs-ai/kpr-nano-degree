{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6114466f",
   "metadata": {},
   "source": [
    "# Diamonds Dataset - Feature Engineering Techniques\n",
    "In this notebook, we explore two common feature engineering techniques: one for categorical variables and one for numerical variables, using the diamonds dataset from seaborn. These steps are designed to help prepare the dataset for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4c927",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset\n",
    "First, we load the diamonds dataset and explore the types of features available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb329ac3",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "The diamonds dataset contains both numerical features (e.g., `carat`, `depth`, `price`) and categorical features (e.g., `cut`, `color`, `clarity`). Understanding the types of features helps us decide the appropriate feature engineering techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e9331",
   "metadata": {},
   "source": [
    "## Feature Engineering Technique 1: Encoding Categorical Variables\n",
    "### Technique: One-Hot Encoding\n",
    "Categorical variables like `cut`, `color`, and `clarity` are non-numerical. Many machine learning models require numerical input, so we use **One-Hot Encoding**.\n",
    "\n",
    "**Why One-Hot Encoding?**\n",
    "- It converts each category into a binary column (0 or 1), allowing the model to learn without assuming any ordinal relationship.\n",
    "\n",
    "**Steps:**\n",
    "1. Identify the categorical columns.\n",
    "2. Apply the `pd.get_dummies()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a1f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding to the categorical columns\n",
    "diamonds_encoded = pd.get_dummies(diamonds, columns=['cut', 'color', 'clarity'], drop_first=True)\n",
    "diamonds_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a91ba2",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "The dataset now has additional binary columns for each category of `cut`, `color`, and `clarity`, suitable for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48144363",
   "metadata": {},
   "source": [
    "## Feature Engineering Technique 2: Scaling Numerical Variables\n",
    "### Technique: Standardization (Z-score Scaling)\n",
    "Numerical variables like `carat`, `depth`, `table`, and `price` often have different ranges. We use **Standardization** to bring these variables to a common scale.\n",
    "\n",
    "**Why Standardization?**\n",
    "- It ensures all features contribute equally during modeling.\n",
    "- Many algorithms, such as linear regression, perform better when numerical features are standardized.\n",
    "\n",
    "**Steps:**\n",
    "1. Identify the numerical columns.\n",
    "2. Use `StandardScaler` from `scikit-learn` to scale the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449be12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numerical columns\n",
    "numerical_cols = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "\n",
    "# Instantiate the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling to the numerical columns\n",
    "diamonds_scaled = diamonds_encoded.copy()\n",
    "diamonds_scaled[numerical_cols] = scaler.fit_transform(diamonds_encoded[numerical_cols])\n",
    "diamonds_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6ff604",
   "metadata": {},
   "source": [
    "**Result:**\n",
    "The numerical columns are now standardized, with values around 0, making them comparable and suitable for algorithms sensitive to feature scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b72f8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- **One-Hot Encoding** for Categorical Variables: Converts categories into binary columns, suitable for non-ordinal data.\n",
    "- **Standardization** for Numerical Variables: Scales data to have a mean of 0 and a standard deviation of 1, improving model performance.\n",
    "\n",
    "These techniques help prepare the diamonds dataset for machine learning, ensuring categorical and numerical data are correctly formatted and scaled."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
